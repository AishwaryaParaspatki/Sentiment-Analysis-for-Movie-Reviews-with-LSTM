{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples = 25000\n",
      "Number of testing samples = 25000\n",
      "X_train vector shape = (25000, 100)\n",
      "X_test vector shape = (25000, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashpa\\Anaconda3.7\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 103s 4ms/step - loss: 0.4696 - accuracy: 0.7750 - val_loss: 0.3570 - val_accuracy: 0.8440\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 112s 4ms/step - loss: 0.3091 - accuracy: 0.8724 - val_loss: 0.3824 - val_accuracy: 0.8284\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 112s 4ms/step - loss: 0.2602 - accuracy: 0.8968 - val_loss: 1.3763 - val_accuracy: 0.7949\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 131s 5ms/step - loss: 0.2221 - accuracy: 0.9142 - val_loss: 0.4077 - val_accuracy: 0.8394\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 125s 5ms/step - loss: 0.1914 - accuracy: 0.9269 - val_loss: 0.3918 - val_accuracy: 0.8468\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 109s 4ms/step - loss: 0.1631 - accuracy: 0.9402 - val_loss: 0.6940 - val_accuracy: 0.7925\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 111s 4ms/step - loss: 0.1411 - accuracy: 0.9488 - val_loss: 0.5187 - val_accuracy: 0.8344\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 112s 4ms/step - loss: 0.1218 - accuracy: 0.9561 - val_loss: 0.4785 - val_accuracy: 0.8337\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 109s 4ms/step - loss: 0.1029 - accuracy: 0.9632 - val_loss: 0.4743 - val_accuracy: 0.8294\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 109s 4ms/step - loss: 0.0796 - accuracy: 0.9726 - val_loss: 0.7051 - val_accuracy: 0.8254\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Import IMDB dataset\n",
    "training_set, testing_set = imdb.load_data(num_words = 10000)\n",
    "X_train, y_train = training_set\n",
    "X_test, y_test = testing_set\n",
    "\n",
    "print(\"Number of training samples = {}\".format(X_train.shape[0]))\n",
    "print(\"Number of testing samples = {}\".format(X_test.shape[0]))\n",
    "\n",
    "# Zero-Padding\n",
    "X_train_padded = sequence.pad_sequences(X_train, maxlen= 100)\n",
    "X_test_padded = sequence.pad_sequences(X_test, maxlen= 100)\n",
    "\n",
    "print(\"X_train vector shape = {}\".format(X_train_padded.shape))\n",
    "print(\"X_test vector shape = {}\".format(X_test_padded.shape))\n",
    "\n",
    "# Model Building\n",
    "def train_model(Optimizer, X_train, y_train, X_val, y_val):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim = 10000, output_dim = 128))\n",
    "    model.add(LSTM(units=128))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer = Optimizer, metrics=['accuracy'])\n",
    "    scores = model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_val, y_val))\n",
    "    return scores, model\n",
    "\n",
    "# Train Model\n",
    "RMSprop_score, RMSprop_model = train_model(Optimizer = 'RMSprop', X_train=X_train_padded, y_train=y_train, X_val=X_test_padded, y_val=y_test)\n",
    "\n",
    "# Plot accuracy per epoch\n",
    "plt.plot(range(1,11), RMSprop_score.history['accuracy'], label='Training Accuracy') \n",
    "plt.plot(range(1,11), RMSprop_score.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.axis([1, 10, 0, 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Train and Validation Accuracy using RMSprop Optimizer')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "y_test_pred = RMSprop_model.predict_classes(X_test_padded) \n",
    "c_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "ax = sns.heatmap(c_matrix, annot=True, xticklabels=['Negative Sentiment', 'Positive Sentiment'], yticklabels=['Negative Sentiment', 'Positive Sentiment'], cbar=False, cmap='Blues', fmt='g')\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
